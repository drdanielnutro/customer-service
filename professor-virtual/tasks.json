{
  "project": "professor-virtual-adk-compliance",
  "description": "Tasks for updating the Professor Virtual system to comply with Google ADK standards",
  "created_at": "2025-01-29",
  "tasks": [
    {
      "id": 1,
      "title": "Update config.py with artifact_service and GCS configurations",
      "description": "Add configuration fields for artifact_service and GCS storage to support proper ADK integration",
      "status": "pending",
      "dependencies": [],
      "priority": "high",
      "details": "PROBLEMA: Falta configuração do artifact_service e GCS\n\nREMOVER/ADICIONAR após a linha 38:\n```python\n    API_KEY: str | None = Field(default=\"\")\n```\n\nADICIONAR:\n```python\n    API_KEY: str | None = Field(default=\"\")\n    \n    # Configurações do Artifact Service\n    artifact_storage_type: str = Field(default=\"memory\", description=\"memory ou gcs\")\n    gcs_bucket_name: str = Field(default=\"adk-professor-virtual-artifacts\")\n    \n    # Configuração de ambiente\n    is_production: bool = Field(default=False)\n```",
      "testStrategy": "Verify that config.py contains the new fields (artifact_storage_type, gcs_bucket_name, is_production) and that they can be properly imported and used in agent.py"
    },
    {
      "id": 2,
      "title": "Modify agent.py to include Runner and artifact_service initialization",
      "description": "Update agent.py to properly initialize the Runner with artifact_service and session_service according to ADK standards",
      "status": "pending",
      "dependencies": [1],
      "priority": "high",
      "details": "PROBLEMA: Falta inicialização do artifact_service no Runner\n\n❌ CÓDIGO ATUAL (linhas 24-40):\n```python\nroot_agent = Agent(\n    model=configs.agent_settings.model,\n    global_instruction=\"\",\n    instruction=INSTRUCTION,\n    name=configs.agent_settings.name,\n    tools=[\n        transcrever_audio,\n        analisar_necessidade_visual,\n        analisar_imagem_educacional,\n        gerar_audio_tts,\n    ],\n    generate_content_config=configs.generate_content_config,\n    before_tool_callback=before_tool,\n    after_tool_callback=after_tool,\n    before_agent_callback=before_agent,\n    before_model_callback=rate_limit_callback,\n)\n```\n\n✅ SUBSTITUIR POR:\n```python\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.artifacts import InMemoryArtifactService, GcsArtifactService\n\n# Configurar artifact service baseado no ambiente\nif configs.is_production and configs.artifact_storage_type == \"gcs\":\n    artifact_service = GcsArtifactService(bucket_name=configs.gcs_bucket_name)\nelse:\n    artifact_service = InMemoryArtifactService()\n\n# Configurar session service\nsession_service = InMemorySessionService()\n\n# Criar o agente\nroot_agent = Agent(\n    model=configs.agent_settings.model,\n    global_instruction=\"\",\n    instruction=INSTRUCTION,\n    name=configs.agent_settings.name,\n    tools=[\n        transcrever_audio,\n        analisar_necessidade_visual,\n        analisar_imagem_educacional,\n        gerar_audio_tts,\n    ],\n    generate_content_config=configs.generate_content_config,\n    before_tool_callback=before_tool,\n    after_tool_callback=after_tool,\n    before_agent_callback=before_agent,\n    before_model_callback=rate_limit_callback,\n)\n\n# Criar o Runner com artifact service\nrunner = Runner(\n    agent=root_agent,\n    app_name=configs.app_name,\n    session_service=session_service,\n    artifact_service=artifact_service  # CRÍTICO: Deve ser configurado\n)\n```",
      "testStrategy": "Verify that agent.py imports Runner, InMemorySessionService, InMemoryArtifactService, and GcsArtifactService; initializes artifact_service based on environment config; creates session_service; and properly initializes the Runner with all required services"
    },
    {
      "id": 3,
      "title": "Update analisar_imagem_educacional.py to be async and fix deprecated APIs",
      "description": "Convert analisar_imagem_educacional function to async and fix deprecated session.get_artifact API and incorrect artifact data access",
      "status": "pending",
      "dependencies": [2],
      "priority": "high",
      "details": "### PROBLEMA 1: API inexistente `session.get_artifact`\n\n**❌ REMOVER (linhas 48-51):**\n```python\n        # Obter artefato - mantém lógica original\n        artifact = tool_context.session.get_artifact(nome_artefato_imagem)\n        if not artifact:\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n        # Obter artefato usando API correta\n        artifact = await tool_context.load_artifact(nome_artefato_imagem)\n        if not artifact:\n```\n\n### PROBLEMA 2: Função deve ser assíncrona\n\n**❌ REMOVER (linha 42):**\n```python\ndef analisar_imagem_educacional(nome_artefato_imagem: str, contexto_pergunta: str, tool_context: ToolContext) -> Dict[str, Any]:\n```\n\n**✅ SUBSTITUIR POR:**\n```python\nasync def analisar_imagem_educacional(nome_artefato_imagem: str, contexto_pergunta: str, tool_context: ToolContext) -> Dict[str, Any]:\n```\n\n### PROBLEMA 3: Acesso incorreto aos dados do artifact\n\n**❌ REMOVER (linha 57):**\n```python\n        imagem_bytes = artifact.content\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n        # Extrair dados do artifact corretamente\n        if hasattr(artifact, 'inline_data') and artifact.inline_data:\n            imagem_bytes = artifact.inline_data.data\n            mime_type = artifact.inline_data.mime_type\n        else:\n            return {\n                \"erro\": \"Formato de artifact inválido\",\n                \"sucesso\": False,\n                \"qualidade_adequada\": False\n            }\n```",
      "testStrategy": "Verify that analisar_imagem_educacional function is async, uses await tool_context.load_artifact() instead of session.get_artifact(), and correctly accesses artifact data through artifact.inline_data.data with proper error handling for invalid artifact formats"
    },
    {
      "id": 4,
      "title": "Update gerar_audio_tts.py to be async and fix deprecated APIs",
      "description": "Convert gerar_audio_tts function to async and fix deprecated session.create_artifact API usage",
      "status": "pending",
      "dependencies": [2],
      "priority": "high",
      "details": "### PROBLEMA 1: API inexistente `session.create_artifact`\n\n**❌ REMOVER (linhas 119-124):**\n```python\n        # Salvar usando a API existente do projeto\n        tool_context.session.create_artifact(\n            name=nome_artefato,\n            content=audio_bytes,\n            mime_type=\"audio/mpeg\"\n        )\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n        # Salvar usando a API correta do ADK\n        audio_part = types.Part.from_data(\n            data=audio_bytes,\n            mime_type=\"audio/mpeg\"\n        )\n        version = await tool_context.save_artifact(nome_artefato, audio_part)\n```\n\n### PROBLEMA 2: Função deve ser assíncrona\n\n**❌ REMOVER (linha 41):**\n```python\ndef gerar_audio_tts(texto: str, tool_context: ToolContext, velocidade: float = 1.0, voz: str = \"pt-BR-Standard-A\") -> Dict[str, Any]:\n```\n\n**✅ SUBSTITUIR POR:**\n```python\nasync def gerar_audio_tts(texto: str, tool_context: ToolContext, velocidade: float = 1.0, voz: str = \"pt-BR-Standard-A\") -> Dict[str, Any]:\n```\n\n### PROBLEMA 3: Adicionar versão no retorno\n\n**❌ REMOVER (linhas 142-148):**\n```python\n        return {\n            \"sucesso\": True,\n            \"nome_artefato_gerado\": nome_artefato,\n            \"tamanho_caracteres\": len(texto),\n            \"tamanho_bytes\": len(audio_bytes),\n            \"voz_utilizada\": gemini_voice,\n            \"velocidade\": velocidade\n        }\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n        return {\n            \"sucesso\": True,\n            \"nome_artefato_gerado\": nome_artefato,\n            \"versao\": version,  # Adicionar versão retornada\n            \"tamanho_caracteres\": len(texto),\n            \"tamanho_bytes\": len(audio_bytes),\n            \"voz_utilizada\": gemini_voice,\n            \"velocidade\": velocidade\n        }\n```",
      "testStrategy": "Verify that gerar_audio_tts function is async, uses await tool_context.save_artifact() with types.Part.from_data() instead of session.create_artifact(), and includes version field in the return object"
    },
    {
      "id": 5,
      "title": "Update transcrever_audio.py to be async and fix deprecated APIs",
      "description": "Convert transcrever_audio function to async and fix deprecated artifact loading/saving APIs, including updating the auxiliary function _buscar_audio_na_mensagem",
      "status": "pending",
      "dependencies": [2],
      "priority": "high",
      "details": "### PROBLEMA 1: Método deve ser assíncrono\n\n**❌ REMOVER (linha 46):**\n```python\ndef transcrever_audio(\n```\n\n**✅ SUBSTITUIR POR:**\n```python\nasync def transcrever_audio(\n```\n\n### PROBLEMA 2: load_artifact deve usar await\n\n**❌ REMOVER (linha 61):**\n```python\n        audio_artifact = tool_context.load_artifact(nome_artefato_audio)\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n        audio_artifact = await tool_context.load_artifact(nome_artefato_audio)\n```\n\n### PROBLEMA 3: save_artifact deve usar await\n\n**❌ REMOVER (linha 151):**\n```python\n            versao_salva = tool_context.save_artifact(filename, transcript_artifact)\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n            versao_salva = await tool_context.save_artifact(filename, transcript_artifact)\n```\n\n### PROBLEMA 4: Função auxiliar _buscar_audio_na_mensagem\n\n**❌ REMOVER (linha 227):**\n```python\ndef _buscar_audio_na_mensagem(tool_context: ToolContext) -> Optional[Any]:\n```\n\n**✅ SUBSTITUIR POR:**\n```python\nasync def _buscar_audio_na_mensagem(tool_context: ToolContext) -> Optional[Any]:\n```\n\n**❌ REMOVER (linha 65):**\n```python\n            audio_artifact = _buscar_audio_na_mensagem(tool_context)\n```\n\n**✅ SUBSTITUIR POR:**\n```python\n            audio_artifact = await _buscar_audio_na_mensagem(tool_context)\n```",
      "testStrategy": "Verify that transcrever_audio function is async, uses await with tool_context.load_artifact() and tool_context.save_artifact(), the auxiliary function _buscar_audio_na_mensagem is also async, and all calls to _buscar_audio_na_mensagem use await"
    },
    {
      "id": 6,
      "title": "Create artifact_handler.py for managing frontend uploads",
      "description": "Create a new file to handle file uploads from frontend and create artifacts following ADK standards",
      "status": "pending",
      "dependencies": [2],
      "priority": "high",
      "details": "Novo Arquivo Necessário: `professor_virtual/artifact_handler.py`\n\nCriar este arquivo para gerenciar uploads do frontend:\n\n```python\n\"\"\"Handler para processar uploads e criar artifacts do frontend.\"\"\"\n\nimport base64\nfrom typing import Dict, Any\nfrom google.genai import types\nfrom google.adk.agents.invocation_context import InvocationContext\n\n\nasync def handle_file_upload(\n    file_data: Dict[str, Any],\n    context: InvocationContext\n) -> Dict[str, Any]:\n    \"\"\"\n    Processa upload de arquivo do frontend e cria artifact.\n    \n    Args:\n        file_data: Dict com 'content' (base64), 'mime_type' e 'filename'\n        context: Contexto da invocação ADK\n        \n    Returns:\n        Dict com informações do artifact criado\n    \"\"\"\n    try:\n        # Decodificar base64 se necessário\n        if isinstance(file_data['content'], str):\n            content_bytes = base64.b64decode(file_data['content'])\n        else:\n            content_bytes = file_data['content']\n            \n        # Criar Part do arquivo\n        artifact = types.Part.from_data(\n            data=content_bytes,\n            mime_type=file_data['mime_type']\n        )\n        \n        # Salvar artifact\n        version = await context.save_artifact(\n            filename=file_data['filename'],\n            artifact=artifact\n        )\n        \n        return {\n            \"success\": True,\n            \"filename\": file_data['filename'],\n            \"version\": version,\n            \"size\": len(content_bytes)\n        }\n        \n    except Exception as e:\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n```",
      "testStrategy": "Verify that artifact_handler.py exists in professor_virtual directory, contains handle_file_upload async function with proper imports (base64, types from google.genai, InvocationContext), handles base64 decoding, creates artifacts using types.Part.from_data(), saves artifacts with context.save_artifact(), and returns success/error responses with proper fields"
    },
    {
      "id": 7,
      "title": "Frontend Integration Guidelines (Documentation/Comments)",
      "description": "Document the frontend integration requirements and data format specifications for proper communication with the ADK backend",
      "status": "pending",
      "dependencies": [6],
      "priority": "high",
      "details": "## Modificações no Frontend (Orientações)\n\n### Frontend deve enviar dados no formato:\n\n```json\n{\n  \"action\": \"upload_file\",\n  \"file_data\": {\n    \"content\": \"base64_encoded_content\",\n    \"mime_type\": \"audio/wav\",\n    \"filename\": \"pergunta_aluno_123.wav\"\n  },\n  \"session_id\": \"session_abc\",\n  \"user_id\": \"user_123\"\n}\n```\n\n### Frontend NÃO deve:\n- Esperar que o Runner crie artifacts automaticamente\n- Enviar arquivos binários diretamente no corpo da requisição\n- Usar APIs do ADK diretamente (não há SDK Flutter oficial)\n\n### Frontend DEVE:\n- Converter arquivos para base64 antes de enviar\n- Incluir sempre o MIME type correto\n- Aguardar confirmação com filename e version do backend",
      "testStrategy": "Verify that frontend code (when implemented) follows these guidelines: sends data in the specified JSON format with base64 encoding, includes all required fields (action, file_data with content/mime_type/filename, session_id, user_id), does not expect automatic artifact creation, does not send binary data directly, and properly waits for backend confirmation with filename and version"
    },
    {
      "id": 8,
      "title": "Configure environment variables for Dev/Prod switching",
      "description": "Add environment variables to .env and update config.py to support automatic switching between InMemoryArtifactService (development) and GcsArtifactService (production/Vertex AI)",
      "status": "pending",
      "dependencies": [1],
      "priority": "high",
      "details": "Para não esquecer nenhuma configuração e permitir alternar **InMemoryArtifactService** (desenvolvimento local) e **GcsArtifactService** (produção / Vertex AI) de modo automático, inclua:\n\n### 8.1 Variáveis adicionadas ao `.env`\n\n```dotenv\n# já existentes\nGOOGLE_GENAI_USE_VERTEXAI=0        # 0 = Gemini API local, 1 = Vertex AI\n\n# novas\nARTIFACT_STORAGE_TYPE=             # vazio → será derivado de GOOGLE_GENAI_USE_VERTEXAI\nGCS_BUCKET_NAME=adk-professor-virtual-artifacts\nGOOGLE_CLOUD_PROJECT=seu-projeto-id\nGOOGLE_CLOUD_LOCATION=us-central1\n```\n\n*Se `ARTIFACT_STORAGE_TYPE` ficar vazio, o código escolherá `memory` quando `GOOGLE_GENAI_USE_VERTEXAI=0` e `gcs` quando for `1`.*\n\n### 8.2 Ajuste em `config.py` — derivação automática\n\n```python\nclass Settings(BaseSettings):\n    GOOGLE_GENAI_USE_VERTEXAI: int = Field(0, env=\"GOOGLE_GENAI_USE_VERTEXAI\")\n\n    ARTIFACT_STORAGE_TYPE: str | None = Field(default=None, env=\"ARTIFACT_STORAGE_TYPE\")\n    GCS_BUCKET_NAME: str = Field(default=\"adk-professor-virtual-artifacts\", env=\"GCS_BUCKET_NAME\")\n    GOOGLE_CLOUD_PROJECT: str | None = Field(default=None, env=\"GOOGLE_CLOUD_PROJECT\")\n    GOOGLE_CLOUD_LOCATION: str | None = Field(default=None, env=\"GOOGLE_CLOUD_LOCATION\")\n\n    @property\n    def use_vertex(self) -> bool:\n        return self.GOOGLE_GENAI_USE_VERTEXAI == 1\n\n    @property\n    def artifact_storage(self) -> str:\n        # se explícito, usa; senão, deriva do modo VertexAI\n        return self.ARTIFACT_STORAGE_TYPE or (\"gcs\" if self.use_vertex else \"memory\")\n```",
      "testStrategy": "Verify that .env contains all required environment variables (GOOGLE_GENAI_USE_VERTEXAI, ARTIFACT_STORAGE_TYPE, GCS_BUCKET_NAME, GOOGLE_CLOUD_PROJECT, GOOGLE_CLOUD_LOCATION), config.py has Settings class with all new fields and properties (use_vertex, artifact_storage), and the artifact_storage property correctly derives storage type from GOOGLE_GENAI_USE_VERTEXAI when ARTIFACT_STORAGE_TYPE is not explicitly set"
    },
    {
      "id": 9,
      "title": "Configure GCS permissions for production environment",
      "description": "Set up Service Account permissions and authentication for Google Cloud Storage access in production",
      "status": "pending",
      "dependencies": [1, 2, 8],
      "priority": "high",
      "details": "### 8.4 Permissões GCS em produção\n\n1. Crie ou escolha um **Service Account** com:\n\n   * `Vertex AI User`\n   * `Storage Object Admin` (ou no mínimo `Storage Object Creator` + `Viewer`) no bucket definido em `GCS_BUCKET_NAME`.\n\n2. Defina `GOOGLE_APPLICATION_CREDENTIALS=/caminho/sa-key.json` no ambiente de execução (Cloud Run, Cloud Functions ou máquina local).\n\n3. Verifique que o bucket está na mesma região de `GOOGLE_CLOUD_LOCATION` para reduzir latência.",
      "testStrategy": "Verify that Service Account has Vertex AI User and Storage Object Admin roles, GOOGLE_APPLICATION_CREDENTIALS environment variable points to valid service account key JSON file, bucket exists in GCS and is accessible with configured permissions, and bucket region matches GOOGLE_CLOUD_LOCATION setting"
    },
    {
      "id": 10,
      "title": "Execute recommended testing workflow across environments",
      "description": "Follow the recommended testing workflow to validate artifact storage across development, GCS smoke-test, and production environments",
      "status": "pending",
      "dependencies": [1, 2, 8, 9],
      "priority": "high",
      "details": "### 8.5 Fluxo de testes recomendado\n\n| Etapa                          | Variáveis                                                     | Resultado esperado                                                                                  |\n| ------------------------------ | ------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n| **Dev local**                  | `GOOGLE_GENAI_USE_VERTEXAI=0`                                 | Artifacts em memória, descartados ao reiniciar                                                      |\n| **Smoke-test GCS** (validação) | `GOOGLE_GENAI_USE_VERTEXAI=1` + chave JSON + bucket existente | Arquivos **.wav / .png / .mp3** surgem em `gs://$GCS_BUCKET_NAME/app_name/user_id/session_id/.../0` |\n| **Produção**                   | Igual ao teste GCS + deploy Vertex AI                         | Mesmo comportamento, agora com modelo Vertex AI                                                     |",
      "testStrategy": "Execute the three-stage testing workflow: 1) Dev local: verify artifacts are stored in memory with GOOGLE_GENAI_USE_VERTEXAI=0, 2) Smoke-test GCS: verify .wav/.png/.mp3 files appear in GCS bucket path with GOOGLE_GENAI_USE_VERTEXAI=1 and proper authentication, 3) Production: verify same GCS behavior with full Vertex AI deployment"
    }
  ]
}